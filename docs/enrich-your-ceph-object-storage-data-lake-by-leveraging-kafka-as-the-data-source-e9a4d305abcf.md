# é€šè¿‡åˆ©ç”¨ Kafka ä½œä¸ºæ•°æ®æºæ¥ä¸°å¯Œæ‚¨çš„ Ceph å¯¹è±¡å­˜å‚¨æ•°æ®æ¹–

> åŸæ–‡ï¼š<https://itnext.io/enrich-your-ceph-object-storage-data-lake-by-leveraging-kafka-as-the-data-source-e9a4d305abcf?source=collection_archive---------4----------------------->

*äº†è§£å¦‚ä½•ä½¿ç”¨ Secor å°† Kafka æ¶ˆæ¯ç§»åŠ¨åˆ° Ceph S3 å¯¹è±¡å­˜å‚¨ä¸­*

![](img/eae126a47a40a47c29d86c02d43ab43b.png)

> å¦‚æœä½ çš„ä¸šåŠ¡æ˜¯ä½ çš„å¤ªé˜³ç³»ï¼Œé‚£ä¹ˆä½ çš„æ•°æ®å°±æ˜¯å¤ªé˜³ï¼Œå®ƒæ—¢æœ‰å¼•åŠ›åˆæœ‰è´¨é‡ï¼Œä¸€åˆ‡éƒ½å›´ç»•ç€å®ƒè½¬ï¼Œå®ƒå¿…é¡»æ°¸è¿œå­˜åœ¨â€”â€”æˆ‘è‡ªå·±

# ä»‹ç»

Kafka æ˜¯æœ€å—æ¬¢è¿çš„æ¶ˆæ¯ç³»ç»Ÿä¹‹ä¸€ï¼Œç”¨äºå®æ—¶æ•°æ®æµï¼Œæ”¶é›†å¤§æ•°æ®ï¼Œæˆ–è¿›è¡Œå®æ—¶åˆ†ææˆ–ä¸¤è€…å…¼è€Œæœ‰ä¹‹ã€‚Kafka ç”¨äºå°†æ•°æ®æµå¯¼å…¥æ•°æ®æ¹–ã€åº”ç”¨ç¨‹åºå’Œå®æ—¶æµåˆ†æç³»ç»Ÿã€‚

![](img/313250f966b671cc4bd047cf3f1c8334.png)

Apache Kafka ç”¨ä¾‹

# Kafka:æ•°æ®æ¹–çš„ä¸»è¦æ¥æº

Kafka æ˜¯ä¸€æŠŠç‘å£«å†›åˆ€ï¼Œç”¨äºæ„å»ºå¯æ‰©å±•çš„å®¹é”™æ¶æ„ã€‚è™½ç„¶æ‚¨å¯ä»¥åœ¨å„ç§ç”¨ä¾‹ä¸­ä½¿ç”¨ Kafkaï¼Œä½†è¿™ç¯‡æ–‡ç« å°†è¯¦ç»†ä»‹ç»å¦‚ä½•åˆ©ç”¨ Kafka ä½œä¸ºæ‚¨çš„æ•°æ®æ¹–çš„ä¸»è¦æ¥æºã€‚

![](img/3da2057c033097f97a16cc9ec5751353.png)

ä¸Šé¢æ˜¾ç¤ºçš„é«˜çº§æ¶æ„å¾ˆç®€å•ï¼Œæ‚¨å…³å¿ƒçš„é•¿æœŸå­˜å‚¨æ•°æ®ï¼Œæ— è®ºæ˜¯ä¸ä¸šåŠ¡å†³ç­–ç›¸å…³ã€åˆ†æç›¸å…³è¿˜æ˜¯ä¸åˆè§„æ€§ç›¸å…³ï¼Œæˆ–è€…åªæ˜¯æ‚¨ä¸æƒ³åˆ é™¤è¿™äº›æ•°æ®ï¼Œæ‚¨éƒ½å¯ä»¥é€‰æ‹©å°† Kafka ä¸­çš„æ•°æ®è½¬å‚¨åˆ°ç¬¦åˆ S3 æ ‡å‡†çš„å…±äº«å¯¹è±¡å­˜å‚¨ä¸­(å¦‚ Ceph)ã€‚S3 å’Œ S3A æ¥å£æ— å¤„ä¸åœ¨ï¼Œå‡ ä¹æ‰€æœ‰æ‚¨å–œæ¬¢çš„å·¥å…·éƒ½æ”¯æŒè¿™äº›åè®®ã€‚ä½ æ°¸è¿œä¸ä¼šè§‰å¾—è‡ªå·±è¢«é”åœ¨é‡Œé¢ã€‚

å¯¹äºç»¿åœ°éƒ¨ç½²ï¼Œå¦‚æœæ‚¨è¦åœ¨å…¬å…±äº‘ä¸Šæ„å»ºæ•°æ®åŸºç¡€æ¶æ„ï¼Œå¯ä»¥ä½¿ç”¨ AWSã€GCPã€Azure å’Œ Oracle Cloudã€‚æ‚¨æ‹¥æœ‰æ¥è‡ªå„ä¸ªæä¾›å•†çš„å¯¹è±¡å­˜å‚¨æœåŠ¡ï¼Œæ‚¨å¯ä»¥åˆ©ç”¨å®ƒæ¥æ„å»ºè¿™ä¸ªä½“ç³»ç»“æ„ã€‚

å¯¹äºå†…éƒ¨ç»¿åœ°/æ£•åœ°éƒ¨ç½²ï¼Œåœ¨ä¸ºæ‚¨çš„æ¶æ„é€‰æ‹©ç»„ä»¶æ—¶ï¼Œæ‚¨éœ€è¦éå¸¸è°¨æ…ã€‚å¦‚æœä½ çš„ä¸šåŠ¡æ˜¯ä½ çš„å¤ªé˜³ç³»ï¼Œé‚£ä¹ˆä½ çš„æ•°æ®å°±æ˜¯å¤ªé˜³ï¼Œå®ƒæ—¢æœ‰å¼•åŠ›åˆæœ‰è´¨é‡ã€‚ä¸€åˆ‡éƒ½å›´ç»•ç€å®ƒï¼Œå®ƒå¿…é¡»æ°¸ç”Ÿã€‚

å…¬å…±äº‘ä»¥è¾ƒä½çš„æˆæœ¬ä¸ºæ‚¨å¸¦æ¥çµæ´»æ€§ã€‚æœ‰äº† Snow Ball / Snow Mobile è¿™æ ·çš„æœåŠ¡ï¼ŒæŠŠè‡ªå·±å¤šå¹´ç§¯ç´¯çš„æ•°æ®è½¬ç§»åˆ°å…¬æœ‰äº‘å¯¹è±¡å­˜å‚¨æœåŠ¡ä¸Šå¹¶ä¸æ˜¯è¶…çº§å›°éš¾çš„äº‹æƒ…ã€‚æœ€è¢«å¿½è§†çš„æƒ³æ³•æ˜¯â€œ*å¦‚ä½•ä»å…¬å…±äº‘æœåŠ¡*æŠŠä½ çš„æ•°æ®å¸¦å›å®¶â€ã€‚åœ¨äº‘è®¡ç®—å·¨å¤´å‘å¸ƒçš„ä»»ä½•äº§å“å’ŒæœåŠ¡å…¬å‘Šä¸­ï¼Œæ‚¨æ˜¯å¦å¬è¯´è¿‡ä»–ä»¬ä¸­çš„ä»»ä½•ä¸€å®¶æ¨å‡ºäº†ä¸€é¡¹æœåŠ¡ï¼Œå¯ä»¥å¸®åŠ©æ‚¨ä»¥åˆç†çš„æˆæœ¬å°†å­˜å‚¨åœ¨ä»–ä»¬çš„ä»»ä½•æœåŠ¡ä¸­çš„æ•°æ®å¤§è§„æ¨¡ç§»åŠ¨åˆ°æ‚¨çš„å†…éƒ¨ä½ç½®ï¼Ÿ

> å…¬å…±äº‘==é”å®šä¸“æœ‰æŠ€æœ¯

å¦‚æœæ‚¨å·²ç»æˆ˜ç•¥æ€§åœ°é€‰æ‹©å°†æ‚¨çš„è®¡ç®—ä¿ç•™åœ¨æœ¬åœ°ï¼Œé‚£ä¹ˆæ„å»ºæ‚¨è‡ªå·±çš„æœ¬åœ°å¯¹è±¡å­˜å‚¨æœåŠ¡ä½œä¸ºæ‚¨çš„å…±äº«æ•°æ®å­˜å‚¨åº“æ˜¯å®Œå…¨æœ‰æ„ä¹‰çš„ã€‚å¼€æºæ•°æ®å­˜å‚¨è§£å†³æ–¹æ¡ˆï¼Œå¦‚ Red Hat Ceph Storage/Red Hat open shift Container Storageï¼Œä¸ä»…å¸®åŠ©æ‚¨è·å¾—å¯¹æ•°æ®çš„å®Œå…¨æ§åˆ¶ï¼Œè¿˜ä¸ºæ‚¨é¢å‘æœªæ¥çš„æ•°æ®æœåŠ¡æä¾›äº†ä¸€ä¸ªç»æµé«˜æ•ˆä¸”å¯æ‰©å±•çš„é€‰é¡¹ã€‚ä½ åœ¨è¿™ç§æƒ…å†µä¸‹è€ƒè™‘ HDFS çš„æ—¥å­å·²ç»ä¸€å»ä¸å¤è¿”äº†ã€‚HDFS åœ¨è¿‡å»åå¹´è¡¨ç°å‡ºè‰²ï¼Œä½ åº”è¯¥æŠ•èµ„äºç¬¦åˆè¡Œä¸šæ ‡å‡†ã€é¢å‘æœªæ¥çš„æœ¬åœ°äº‘è§£å†³æ–¹æ¡ˆï¼Œå¦‚ Ceph S3 å¯¹è±¡å­˜å‚¨ã€‚

# å°†æ•°æ®ä» Kafka ç§»åŠ¨åˆ° Ceph S3 å¯¹è±¡å­˜å‚¨

æœ‰å¤šç§æ–¹æ³•å¯ä»¥å°†æ•°æ®ä» Kafka ä¸»é¢˜è½¬ç§»åˆ° Ceph S3 å¯¹è±¡å­˜å‚¨ï¼Œä¾‹å¦‚ä½¿ç”¨å¼€æºå·¥å…·ï¼Œå¦‚ [Secor(æœ€åˆæ¥è‡ª Pinterest )](https://github.com/pinterest/secor) ã€Apache-CamelğŸªS3 è¿æ¥å™¨([è§æˆ‘çš„å¦ä¸€ä¸ªåšå®¢](https://medium.com/@karansingh010/exporting-data-from-apache-kafka-red-hat-amq-streams-topics-to-s3-using-apache-camel-connector-66a56af490e))æˆ–æ±‡åˆçš„å¡å¤«å¡ S3 è¿æ¥å™¨ã€‚

åœ¨è¿™ç¯‡æ–‡ç« ä¸­ï¼Œæˆ‘ä»¬å°†æ·±å…¥æ¢è®¨å¦‚ä½•åœ¨ OpenShift ä¸Šéƒ¨ç½² Secorï¼Œå¹¶å°†å…¶é…ç½®ä¸ºå°† Kafka ä¸»é¢˜æ¶ˆæ¯ç§»åŠ¨åˆ° Red Hat OpenShift å®¹å™¨å­˜å‚¨ S3 å¯¹è±¡å­˜å‚¨æœåŠ¡ã€‚

![](img/8a1bf3f56a6f4665f14c107d074b821c.png)

## å…ˆå†³æ¡ä»¶

*   è¿è¡Œ RedHat OpenShift 4 é›†ç¾¤
*   è¿è¡Œ Red Hat OpenShift å®¹å™¨å­˜å‚¨ 4

## å±¥è¡Œ

**ç¬¬ 1 éƒ¨åˆ†:åœ¨ OpenShift ä¸Šè®¾ç½® Kafka é›†ç¾¤**

*   éªŒè¯æ‚¨çš„ OpenShift é›†ç¾¤

```
oc get nodes
oc get sc
```

*   åœ¨ OpenShift ä¸Šéƒ¨ç½² Kafka é›†ç¾¤

```
oc new-project kafka-to-s3 wget[https://github.com/confluentinc/cp-helm-charts/releases/download/v5.5.0/cp-helm-charts-0.5.0.tgz](https://github.com/confluentinc/cp-helm-charts/releases/download/v5.5.0/cp-helm-charts-0.5.0.tgz)tar -xvf cp-helm-charts-0.5.0.tgz
```

*   ç¼–è¾‘ Kafka å¤´ç›”å›¾è¡¨å€¼æ–‡ä»¶`vim cp-helm-charts/values.yaml`ï¼Œä¸º Zookeeper å’Œ Kafka èˆ±æ·»åŠ æŒä¹…å­˜å‚¨ã€‚è¿è¡Œ`oc get sc`è·å–æ‚¨çš„ OCP å—å­˜å‚¨ç±»çš„åç§°

![](img/178b7d83484fc17391cc3c58acac04ec.png)

*   ç¦ç”¨ç›®å‰ä¸ç›¸å…³çš„å…¶ä»–æœåŠ¡

![](img/fbfea41bcfe64f9c73fc140e37fb0141.png)

*   è¿™ä¸ª Kafka helm å›¾è¡¨ä½¿ç”¨éœ€è¦ root æƒé™çš„ docker æ˜ åƒï¼Œè°ƒæ•´ OCP å®‰å…¨ä¸Šä¸‹æ–‡çº¦æŸæ¥å¯ç”¨å®ƒ

```
oc adm policy add-scc-to-user anyuid -z default
```

*   å®‰è£…å¡å¤«å¡

```
helm install cp-helm-charts --generate-name -n kafka-to-s3
oc get all -n kafka-to-s3
```

**ç¬¬ 2 éƒ¨åˆ†:å¯ç”¨ Ceph S3 å¯¹è±¡å­˜å‚¨æœåŠ¡**

*   ä½¿ç”¨`oc project openshift-storage`åˆ‡æ¢åˆ°`openshift-storage`é¡¹ç›®
*   ç”¨ä»¥ä¸‹å†…å®¹åˆ›å»ºä¸€ä¸ª CR æ–‡ä»¶`ceph_rgw_object_store.yaml`

```
apiVersion: v1
items:
- apiVersion: ceph.rook.io/v1
  kind: CephObjectStore
  metadata:
    generation: 1
    name: s3a
    namespace: openshift-storage
  spec:
    dataPool:
      crushRoot: ""
      deviceClass: ""
      erasureCoded:
        algorithm: ""
        codingChunks: 0
        dataChunks: 0
      failureDomain: zone
      replicated:
        size: 3
    gateway:
      allNodes: false
      instances: 1
      placement:
        nodeAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            nodeSelectorTerms:
            - matchExpressions:
              - key: cluster.ocs.openshift.io/openshift-storage
                operator: Exists
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
          - podAffinityTerm:
              labelSelector:
                matchExpressions:
                - key: app
                  operator: In
                  values:
                  - rook-ceph-rgw
              topologyKey: kubernetes.io/hostname
            weight: 100
        tolerations:
        - effect: NoSchedule
          key: node.ocs.openshift.io/storage
          operator: Equal
          value: "true"
      port: 80
      resources:
        limits:
          cpu: "1"
          memory: 2Gi
        requests:
          cpu: "1"
          memory: 1Gi
      securePort: 0
      sslCertificateRef: ""
    metadataPool:
      crushRoot: ""
      deviceClass: ""
      erasureCoded:
        algorithm: ""
        codingChunks: 0
        dataChunks: 0
      failureDomain: zone
      replicated:
        size: 3
kind: List
metadata:
  resourceVersion: ""
  selfLink: ""
```

*   åº”ç”¨ CR `oc create -f ceph_rgw_object_store.yaml -n openshift-storage`
*   è¿™å°†è§¦å‘ Ceph RGW åŠèˆ±çš„åˆ›å»ºï¼Œä½¿ç”¨`oc get po | grep -i rgw`è¿›è¡ŒéªŒè¯
*   é€šè¿‡åº”ç”¨ä»¥ä¸‹ CR æ–‡ä»¶åˆ›å»ºå¯¹è±¡å­˜å‚¨ç”¨æˆ·

```
apiVersion: ceph.rook.io/v1
kind: CephObjectStoreUser
metadata:
  name: s3user1
  namespace: openshift-storage
spec:
  store: s3a
  displayName: "s3 user1"
```

å¦‚æœæ‚¨åœ¨æ²¡æœ‰æœ‰æ•ˆ SSL è¯ä¹¦çš„ OpenShift ç¯å¢ƒä¸­å°è¯•è¿™æ ·åšï¼Œé‚£ä¹ˆæ‚¨å¿…é¡»ç”Ÿæˆ Let's Encrypt è¯ä¹¦ï¼Œå¹¶å°†è¿™äº›è¯ä¹¦åº”ç”¨åˆ° OpenShift é›†ç¾¤ã€‚SSL è¯ä¹¦çš„ç¼ºå¤±ä¼šç»™ Secor è”ç³»ä¸å®‰å…¨çš„ S3 ç«¯ç‚¹å¸¦æ¥é—®é¢˜ã€‚[ä½¿ç”¨æˆ‘çš„å¦ä¸€ä¸ªåšå®¢](https://medium.com/@karansingh010/lets-automate-let-s-encrypt-tls-certs-for-openshift-4-211d6c081875)æ¥å®ç°ä½¿ç”¨ Let's Encrypt çš„ SSL è¯ä¹¦ã€‚

**ç¬¬ 3 éƒ¨åˆ†:éªŒè¯å¯¹ OpenShift å®¹å™¨å­˜å‚¨å¯¹è±¡æœåŠ¡çš„è®¿é—®**

*   å‡ºå£`AWS_ACCESS_KEY` `AWS_SECRET_KEY` `RGW_ENDPOINT`

```
export AWS_ACCESS_KEY_ID=`oc get secret -n openshift-storage rook-ceph-object-user-s3a-s3user1 -o 'jsonpath={.data.AccessKey}' | base64 --decode;echo`export AWS_SECRET_ACCESS_KEY=`oc get -n openshift-storage secret rook-ceph-object-user-s3a-s3user1 -o 'jsonpath={.data.SecretKey}' | base64 --decode;echo`export RGW_ENDPOINT=$(oc get route -n openshift-storage --selector='app=rook-ceph-rgw' -o 'jsonpath={.items..spec.host}')
```

*   å°è¯•ä½¿ç”¨ s3cmd å‘½ä»¤è¡Œå·¥å…·åˆ—å‡ºå’Œåˆ›å»ºå­˜å‚¨æ¡¶

```
s3cmd --access_key=$AWS_ACCESS_KEY_ID --secret_key=$AWS_SECRET_ACCESS_KEY --ssl  --host=$RGW_ENDPOINT  --host-bucket="$RGW_ENDPOINT/%(bucket)" lss3cmd --access_key=$AWS_ACCESS_KEY_ID --secret_key=$AWS_SECRET_ACCESS_KEY --ssl  --host=$RGW_ENDPOINT  --host-bucket="$RGW_ENDPOINT/%(bucket)" mb s3://kafka-to-ceph-s3s3cmd --access_key=$AWS_ACCESS_KEY_ID --secret_key=$AWS_SECRET_ACCESS_KEY --ssl  --host=$RGW_ENDPOINT  --host-bucket="$RGW_ENDPOINT/%(bucket)" ls
```

**ç¬¬å››éƒ¨åˆ†:ä¸å¡å¤«å¡é›†ç¾¤çš„è”ç³»å’Œäº’åŠ¨**

*   ä½¿ç”¨è¿™ä¸ª YAML åˆ›å»ºä¸€ä¸ª Kafka å®¢æˆ·ç«¯

```
oc project kafka-to-s3vim kafka-client.yamlapiVersion: v1kind: Pod
metadata:
  name: kafka-client
spec:
  containers:
  - name: kafka-client
    image: confluentinc/cp-kafka:5.5.0
    command:
      - sh
      - -c
      - "exec tail -f /dev/null"oc create -f kafka-client.yamloc get po
```

*   æŠ“å– Kafka é›†ç¾¤ç«¯ç‚¹

```
oc get svc -n kafka-to-s3 --selector=app=cp-kafka | grep -v None
```

![](img/1117616293894b468edde8bac0e1fb8d.png)

*   ç™»å½• Kafka å®¢æˆ·ç«¯çª—æ ¼ï¼Œä½¿ç”¨`kafka-console-producer`ç”Ÿæˆä¸€äº›æ¶ˆæ¯

```
oc project kafka-to-s3
oc rsh kafka-client## Replace kafka endpoint with your environmentkafka-console-producer --broker-list cp-helm-charts-1595009069-cp-kafka:9092 --topic my-topic
>
```

*   åœ¨`>`æç¤ºç¬¦ä¸‹ç”Ÿæˆå‡ æ¡éšæœºä¿¡æ¯ï¼ŒæŒ‰`ctrl+c`é€€å‡º
*   ä½¿ç”¨`kafka-console-consumer`é‡æ–°è¿æ¥å¹¶åˆ—å‡ºæ‚¨çš„æ¶ˆæ¯ï¼Œç„¶åæŒ‰`ctrl+c`é€€å‡ºã€‚

```
kafka-console-consumer --bootstrap-server cp-helm-charts-1595009069-cp-kafka:9092 --topic my-topic --from-beginning
```

*   å¦‚æœæ‚¨èƒ½å¤ŸæŸ¥çœ‹æ‚¨çš„æ¶ˆæ¯ï¼Œé‚£ä¹ˆåˆ°ç›®å‰ä¸ºæ­¢ä¸€åˆ‡éƒ½å¾ˆé¡ºåˆ©
*   ç”Ÿæˆå‡ æ¡å…³äºå¡å¤«å¡ä¸»é¢˜çš„ä¿¡æ¯

```
cat /etc/sysctl.conf | kafka-console-producer --broker-list cp-helm-charts-1595009069-cp-kafka:9092 --topic my-topic
```

**ç¬¬ 5 éƒ¨åˆ†:éƒ¨ç½² Secor æœåŠ¡**

æ­£å¦‚æœ¬æ–‡å¼•è¨€éƒ¨åˆ†æ‰€è§£é‡Šçš„ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨å¼€æºéƒ¨é—¨é¡¹ç›®(ç”± Pinterest å¼€å‘)å‘ Ceph S3 å¯¹è±¡å­˜å‚¨æœåŠ¡å‘é€ Kafka ä¸»é¢˜æ¶ˆæ¯ã€‚è®©æˆ‘ä»¬åœ¨ OpenShift å®¹å™¨å¹³å°ä¸Šéƒ¨ç½² Secor åº”ç”¨ç¨‹åº

*   åˆ›å»ºä¸€ä¸ªåä¸º`secor-kafka.yaml`çš„ YAML æ–‡ä»¶ã€‚åœ¨åº”ç”¨ä¹‹å‰ï¼Œæ‚¨éœ€è¦æ ¹æ®æ‚¨çš„ç¯å¢ƒæ›´æ”¹ä¸€äº›å˜é‡

```
apiVersion: apps/v1
kind: Deployment
metadata:
  labels:
    app: secor
  name: secor
spec:
  replicas: 1
  selector:
    matchLabels:
      app: secor
  strategy: {}
  template:
    metadata:
      labels:
        app: secor
    spec:
      containers:
      - image: karansingh/secor-0.29-hadoop-2.9.2:latest
        name: secor-0-29-hadoop-2-9-2
        env:
        - name: ZOOKEEPER_PATH
          value: "/"
        - name: ZOOKEEPER_QUORUM
          value: "cp-helm-charts-1595009069-cp-zookeeper:2181"
        - name: KAFKA_SEED_BROKER_HOST
          value: "cp-helm-charts-1595009069-cp-kafka"
        - name: KAFKA_SEED_BROKER_PORT
          value: "9092"
        - name: AWS_ACCESS_KEY
          value: "YOUR_ACCESS_KEY"
        - name: AWS_SECRET_KEY
          value: "YOUR_SECRET_KEY"
        - name: AWS_ENDPOINT
          value: "rook-ceph-rgw-s3a-https-aws-lb-openshift-storage.apps.presto.ceph-s3.com:443"
        - name: AWS_PATH_STYLE_ACCESS
          value: "true"
        - name: SECOR_S3_BUCKET
          value: "kafka-to-ceph-s3"
        - name: SECOR_GROUP
          value: "raw_logs"
        - name: SECOR_S3_PATH
          value: "kafka-messages"
        - name: KAFKA_OFFSETS_STORAGE
          value: "zookeeper"
        - name: SECOR_MAX_FILE_SECONDS
          value: "10"
        - name: SECOR_MAX_FILE_BYTES
          value: "10000"
        - name: SECOR_UPLOAD_MANAGER
          value: "com.pinterest.secor.uploader.S3UploadManager"
        - name: SECOR_MESSAGE_PARSER
          value: "com.pinterest.secor.parser.OffsetMessageParser"
        - name: DEBUG
          value: "True"
        - name: SECOR_KAFKA_TOPIC_FILTER
          value: "my-topic"
        resources: {}
status: {}
```

*   è‡³å°‘ï¼Œä½ éœ€è¦æ”¹å˜å˜é‡çš„å€¼ï¼Œæ¯”å¦‚`ZOOKEEPER_QUORUM` `KAFKA_SEED_BROKER_HOST` `AWS_ACCESS_KEY` `AWS_SECRET_KEY` `AWS_ENDPOINT`
*   ä»¥ä¸‹å‘½ä»¤åº”è¯¥ä¼šç»™æ‚¨æä¾›æ­£ç¡®çš„å€¼

```
oc get svc -n kafka-to-s3  | grep -v Noneexport AWS_ACCESS_KEY_ID=`oc get secret -n openshift-storage rook-ceph-object-user-s3a-s3user1 -o 'jsonpath={.data.AccessKey}' | base64 --decode;echo`export AWS_SECRET_ACCESS_KEY=`oc get -n openshift-storage secret rook-ceph-object-user-s3a-s3user1 -o 'jsonpath={.data.SecretKey}' | base64 --decode;echo`export RGW_ENDPOINT=$(oc get route -n openshift-storage --selector='app=rook-ceph-rgw' -o 'jsonpath={.items..spec.host}')echo $AWS_ACCESS_KEY_ID
echo $AWS_SECRET_ACCESS_KEY
echo $RGW_ENDPOINT
```

![](img/103bb1e2c2efec3f747cb42b0afc8812.png)

å¡å¤«å¡å’ŒåŠ¨ç‰©å›­ç®¡ç†å‘˜ç«¯ç‚¹

*   ä¸€æ—¦æœ‰äº†æ­£ç¡®çš„å€¼ï¼Œæ›´æ–°`secor-kafka.yaml`å¹¶éƒ¨ç½²æ‰‡åŒºæœåŠ¡

```
oc create -f secor-kafka.yaml
oc get all -n kafka-to-s3
```

**ç¬¬ 6 éƒ¨åˆ†:éªŒè¯ Secor ç§»åŠ¨æ•°æ®åˆ° Ceph S3**

ç”±äºæˆ‘ä»¬åœ¨ Kafka ä¸»é¢˜ä¸­å·²ç»æœ‰äº†åä¸º`my-topic`çš„æ¶ˆæ¯ï¼Œåªè¦æ‚¨éƒ¨ç½² secor æœåŠ¡ï¼Œå®ƒå°±ä¼šæ£€æµ‹åˆ°ä¸»é¢˜ä¸­æœ‰ä¸€äº›æœªè¢«ç§»åŠ¨çš„ Kafka æ¶ˆæ¯ï¼Œå®ƒä¼šç«‹å³å¤„ç†è¿™äº›æ¶ˆæ¯ï¼Œå¹¶å°†å®ƒä»¬ç§»åŠ¨åˆ°é€‰å®šçš„ Ceph S3 æ¡¶ä¸­ã€‚

*   è¦çœ‹åˆ°ç¥å¥‡ä¹‹å¤„ï¼Œä¾‹å¦‚ secor å¦‚ä½•å°† Kafka ä¸»é¢˜æ¶ˆæ¯ç§»åŠ¨åˆ° Ceph S3 æ¡¶ï¼Œæ‚¨éœ€è¦è·Ÿè¸ª secor æ—¥å¿—

```
# On one terminal tail secor logsoc logs -f <secor_pod_name>
```

*   åœ¨æ—¥å¿—ä¸­ï¼Œæ‚¨ä¼šçœ‹åˆ°å¦‚ä¸‹æ¡ç›®ï¼Œè¿™éªŒè¯äº† Secor æ­£åœ¨å‘ Ceph S3 bucket å‘é€ Kafka æ¶ˆæ¯

```
2020-07-20 13:56:15,225 [Thread-3] (com.pinterest.secor.uploader.S3UploadManager) INFO  uploading file /mnt/secor_data/message_logs/partition/1_12/my-topic/offset=0/1_0_00000000000000000018 to s3://kafka-to-ceph-s3/raw_logs/my-topic/offset=0/1_0_00000000000000000018 with no encryption
```

![](img/a587933b3394d03b69fd19b2df77af0e.png)

Secor å‘ Ceph S3 é“²æ–—å‘é€ä¿¡æ¯

*   åˆ—å‡º Ceph S3 å­˜å‚¨æ¡¶ï¼Œä»¥éªŒè¯ Ceph å¯¹è±¡å­˜å‚¨æœåŠ¡æ­£åœ¨ä» Kafka æ¥æ”¶æ•°æ®

```
s3cmd --access_key=$AWS_ACCESS_KEY_ID --secret_key=$AWS_SECRET_ACCESS_KEY --ssl  --host=$RGW_ENDPOINT  --host-bucket="$RGW_ENDPOINT/%(bucket)" ls s3://kafka-to-ceph-s3/raw_logs/my-topic/offset=0/
```

![](img/845ece528200b7ef71c0f192b02ef19f.png)

åˆ—å‡º Ceph S3 æ¡¶ä»¥éªŒè¯ Kafka æ¶ˆæ¯çš„è¾“å…¥

# æ‘˜è¦

*   Red Hat OpenShift å®¹å™¨å­˜å‚¨å¯¹è±¡æœåŠ¡ä½¿æ‚¨èƒ½å¤Ÿä¸ºæ‚¨çš„ä¸šåŠ¡å¼€å‘ä¸€ä¸ªæ•°æ®æ¹–åº“ã€‚
*   å¼€æºé¡¹ç›® **Secor** æä¾›äº†ä¸€ç§å°†ä½ çš„ Kafka æ•°æ®è½¬ç§»åˆ° S3 å¯¹è±¡å­˜å‚¨å™¨çš„å¯é æ–¹æ³•
*   Ceph æ˜¯ä¸€ä¸ªç¬¦åˆ S3 æ ‡å‡†çš„å¯æ‰©å±•å¯¹è±¡å­˜å‚¨å¼€æºè§£å†³æ–¹æ¡ˆï¼Œä¸ S3 it éƒ¨é—¨ä¸€èµ·è¿˜æ”¯æŒ S3A åè®®ï¼Œè¿™æ˜¯æ¶ˆè´¹å¯¹è±¡å­˜å‚¨å…¼å®¹æ•°æ®æ¹–è§£å†³æ–¹æ¡ˆçš„è¡Œä¸šæ ‡å‡†æ–¹å¼ã€‚
*   ä¸€æ—¦æ•°æ®è¢«æ¥æ”¶åˆ° Ceph æ•°æ®æ¹–ä¸­ï¼Œå°±å¯ä»¥ä½¿ç”¨æ‚¨é€‰æ‹©çš„å¼•æ“å¯¹å…¶è¿›è¡Œå¤„ç†ï¼Œä½¿ç”¨æ‚¨é€‰æ‹©çš„å·¥å…·å¯¹å…¶è¿›è¡Œå¯è§†åŒ–ã€‚