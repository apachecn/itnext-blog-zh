<html>
<head>
<title>How To Start with Apache Spark and Apache Cassandra</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">å¦‚ä½•ä»Apache Sparkå’ŒApache Cassandraå¼€å§‹</h1>
<blockquote>åŸæ–‡ï¼š<a href="https://itnext.io/how-to-start-with-apache-spark-and-apache-cassandra-886a648bd2fb?source=collection_archive---------0-----------------------#2020-07-23">https://itnext.io/how-to-start-with-apache-spark-and-apache-cassandra-886a648bd2fb?source=collection_archive---------0-----------------------#2020-07-23</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><figure class="is it gp gr iu iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ir"><img src="../Images/bbacd483a7834e0b96648c8e38d085b7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*lF7HnzHyw7I7g9kI.jpg"/></div></div></figure><div class=""/><p id="4636" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">Apache Cassandraæ˜¯ä¸€ä¸ªç‰¹å®šçš„æ•°æ®åº“ï¼Œå¯ä»¥çº¿æ€§æ‰©å±•ã€‚è¿™æ˜¯æœ‰ä»£ä»·çš„:ç‰¹å®šçš„è¡¨æ ¼æ¨¡å‹ã€å¯é…ç½®çš„ä¸€è‡´æ€§å’Œæœ‰é™çš„åˆ†æã€‚è‹¹æœæ¯ç§’åœ¨è¶…è¿‡160ï¼Œ000ä¸ªCassandraå®ä¾‹ä¸Šæ‰§è¡Œæ•°ç™¾ä¸‡æ¬¡æ“ä½œï¼ŒåŒæ—¶æ”¶é›†è¶…è¿‡100 PBsçš„æ•°æ®ã€‚æ‚¨å¯ä»¥é€šè¿‡Apache Sparkå’ŒDataStaxè¿æ¥å™¨ç»•è¿‡è¿™äº›æœ‰é™çš„åˆ†æï¼Œè¿™å°±æ˜¯æœ¬æ–‡çš„å†…å®¹ã€‚</p><figure class="la lb lc ld gt iv"><div class="bz fp l di"><div class="le lf l"/></div></figure><h1 id="cd6a" class="lg lh je bd li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md bi translated">è®¾ç½®</h1><p id="9e5a" class="pw-post-body-paragraph kb kc je kd b ke me kg kh ki mf kk kl km mg ko kp kq mh ks kt ku mi kw kx ky im bi translated">æˆ‘åœ¨Dockerä¸Šä½¿ç”¨è¿‡ä¸€ä¸ªApache CassandraèŠ‚ç‚¹</p><pre class="la lb lc ld gt mj mk ml mm aw mn bi"><span id="37c2" class="mo lh je mk b gy mp mq l mr ms">version: '3'<br/> <br/>services:<br/>  cassandra:<br/>    image: cassandra:latest<br/>    ports:<br/>      - "9042:9042"</span></pre><p id="4f36" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">Apache Spark 3.0ä½œä¸ºshellæ¨å‡ºï¼Œå¸¦æœ‰è¿æ¥å™¨å’ŒCassandraçš„å®¢æˆ·ç«¯åº“ï¼Œè¿™å¯¹äºtimeuuidç±»å‹è½¬æ¢å°†å¾ˆæœ‰ç”¨ã€‚</p><pre class="la lb lc ld gt mj mk ml mm aw mn bi"><span id="1871" class="mo lh je mk b gy mp mq l mr ms">./spark-shell --packages com.datastax.spark:spark-cassandra-connector_2.12:3.0.0-beta,com.datastax.cassandra:cassandra-driver-core:3.9.0</span></pre><p id="7023" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">å¦‚æœCassandraæ²¡æœ‰åœ¨æœ¬åœ°è¿è¡Œï¼Œæ‚¨éœ€è¦é…ç½®å®ƒçš„åœ°å€ã€‚</p><pre class="la lb lc ld gt mj mk ml mm aw mn bi"><span id="1063" class="mo lh je mk b gy mp mq l mr ms">spark.conf.set("spark.cassandra.connection.host", "127.0.0.1")</span></pre><h1 id="365b" class="lg lh je bd li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md bi translated">æ•°æ®</h1><p id="d009" class="pw-post-body-paragraph kb kc je kd b ke me kg kh ki mf kk kl km mg ko kp kq mh ks kt ku mi kw kx ky im bi translated">ä¸ºäº†æµ‹è¯•Spark + Cassandraç»„åˆï¼Œæˆ‘ä½¿ç”¨mockaroo.comç”Ÿæˆäº†ä¸€äº›æ—¥æœŸã€‚è¿™æ˜¯ä¸€ä¸ªä¼ æ„Ÿå™¨åˆ—è¡¨å’Œè¿™äº›ä¼ æ„Ÿå™¨çš„æµ‹é‡å€¼åˆ—è¡¨ã€‚ä½ å¯ä»¥åœ¨GitHubçš„<a class="ae kz" href="https://github.com/zorteran/wiadro-danych-spark-cassandra-101" rel="noopener ugc nofollow" target="_blank">åº“</a>ä¸­æ‰¾åˆ°å®ƒä»¬ã€‚</p><pre class="la lb lc ld gt mj mk ml mm aw mn bi"><span id="57fd" class="mo lh je mk b gy mp mq l mr ms">maciej@ubuntu:~/Desktop/spark_and_cassandra$ head sensor_reads.csv <br/>date,sensor_id,temperature,wind_speed,wind_direction<br/>2020-02-20 13:00:57,11,90.42,72.91,153<br/>2020-05-28 21:31:03,9,51.62,20.07,255<br/>2020-06-04 16:32:02,3,6.68,89.31,309<br/>...</span></pre><h1 id="9d35" class="lg lh je bd li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md bi translated">åœ¨Apache Cassandraä¸­åˆ›å»ºè¡¨æ ¼</h1><p id="c677" class="pw-post-body-paragraph kb kc je kd b ke me kg kh ki mf kk kl km mg ko kp kq mh ks kt ku mi kw kx ky im bi translated">Apache Cassandraæœ‰ä¸€ä¸ªå«åš<em class="mt"> cqlsh </em>çš„ä¸“ç”¨å·¥å…·ã€‚åœ¨Dockerçš„æƒ…å†µä¸‹ï¼Œæ‚¨å¿…é¡»ä½¿ç”¨ä»¥ä¸‹å‘½ä»¤ã€‚</p><pre class="la lb lc ld gt mj mk ml mm aw mn bi"><span id="8bb4" class="mo lh je mk b gy mp mq l mr ms">sudo<!-- --> <!-- -->docker exec<!-- --> <!-- -->-it container_name cqlsh</span></pre><p id="c3bc" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">é¦–å…ˆï¼Œæˆ‘ä»¬å¿…é¡»åˆ›å»ºä¸€ä¸ªkeyspaceï¼Œè¿™æ˜¯ä¸€ä¸ªç”¨æ¥å­˜æ”¾æˆ‘ä»¬çš„è¡¨çš„åŒ…ã€‚</p><pre class="la lb lc ld gt mj mk ml mm aw mn bi"><span id="ec15" class="mo lh je mk b gy mp mq l mr ms"><strong class="mk jf">CREATE</strong> <!-- -->KEYSPACE spark_playground <strong class="mk jf">WITH</strong> <!-- -->replication = {'class': 'SimpleStrategy', 'replication_factor': 1 };</span></pre><p id="a3b2" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">æœ‰å…³ä¼ æ„Ÿå™¨çš„ä¿¡æ¯å°†ä¿å­˜åœ¨ä¼ æ„Ÿå™¨è¡¨ä¸­ã€‚æ²¡ä»€ä¹ˆå¼‚å¸¸:idï¼Œä½ç½®ï¼Œç»„idã€‚æ³¨æ„ï¼Œä¸»é”®æ˜¯idã€‚å› æ­¤ï¼Œåœ¨æ²¡æœ‰å®Œæ•´çš„è¡¨æ‰«æçš„æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬ä¸ä¼šå¯¹å…¶ä»–åˆ—æ‰§è¡ŒWHEREæ“ä½œ(æˆ‘æåˆ°å…·ä½“çš„æ•°æ®å»ºæ¨¡äº†å—ï¼Ÿ)ï¼Œä½†æ˜¯æŒ‰é”®è¿‡æ»¤ä¼šè¶…çº§å¿«ã€‚</p><pre class="la lb lc ld gt mj mk ml mm aw mn bi"><span id="d98c" class="mo lh je mk b gy mp mq l mr ms"><strong class="mk jf">CREATE</strong> <strong class="mk jf">TABLE</strong> <!-- -->sensors ( sensor_id <strong class="mk jf">int</strong>, location text, group_id <strong class="mk jf">int</strong>, <strong class="mk jf">PRIMARY</strong> <strong class="mk jf">KEY</strong> <!-- -->(sensor_id ));</span></pre><p id="7e69" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">æµ‹é‡å€¼å°†åœ¨sensors_readsè¡¨ä¸­ã€‚å¯†é’¥ç”±ä¼ æ„Ÿå™¨id(åˆ†åŒºå¯†é’¥)å’Œæ—¥æœŸç»„æˆ<a class="ae kz" href="https://docs.datastax.com/en/cql-oss/3.3/cql/cql_reference/uuid_type_r.html" rel="noopener ugc nofollow" target="_blank"> timeuuid </a>(èšç±»å¯†é’¥)ã€‚åˆ†åŒºé”®æŒ‡ç¤ºè®°å½•çš„ä½ç½®(åœ¨å“ªä¸ªèŠ‚ç‚¹ä¸­)ã€‚Timeuuidä½œä¸ºä¸€ä¸ªèšç±»é”®å…è®¸å¯¹è®°å½•è¿›è¡Œæ’åºã€‚å¦‚æœä½ è¿·è·¯äº†ï¼Œçœ‹çœ‹<a class="ae kz" href="https://stackoverflow.com/questions/24949676/difference-between-partition-key-composite-key-and-clustering-key-in-cassandra" rel="noopener ugc nofollow" target="_blank">å…³äº</a>æ ˆæº¢å‡ºçš„è§£é‡Šã€‚æ‚¨å¿…é¡»å°å¿ƒé€‰æ‹©åˆ†åŒºé”®ã€‚<strong class="kd jf">é”™è¯¯çš„é€‰æ‹©ä¼šå¯¼è‡´èŠ‚ç‚¹ä¸Šçš„è´Ÿè½½ä¸å‡åŒ€</strong>ã€‚</p><pre class="la lb lc ld gt mj mk ml mm aw mn bi"><span id="bd25" class="mo lh je mk b gy mp mq l mr ms"><strong class="mk jf">CREATE</strong> <strong class="mk jf">TABLE</strong> <!-- -->sensors_reads ( sensor_id <strong class="mk jf">int</strong>, <strong class="mk jf">date</strong> <!-- -->timeuuid, <strong class="mk jf">temp</strong> <strong class="mk jf">double</strong>, humidity <strong class="mk jf">double</strong>, wind_speed <strong class="mk jf">double</strong>, wind_direction <strong class="mk jf">double</strong>, <strong class="mk jf">PRIMARY</strong> <strong class="mk jf">KEY</strong> <!-- -->(sensor_id, <strong class="mk jf">date</strong> <!-- -->));</span></pre><h1 id="f833" class="lg lh je bd li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md bi translated">ä½¿ç”¨Sparkå‘Cassandraæ·»åŠ æ•°æ®</h1><h2 id="e6ae" class="mo lh je bd li mu mv dn lm mw mx dp lq km my mz lu kq na nb ly ku nc nd mc ne bi translated">åŠ è½½CSVæ–‡ä»¶</h2><pre class="la lb lc ld gt mj mk ml mm aw mn bi"><span id="66ad" class="mo lh je mk b gy mp mq l mr ms">val sensors = spark.read.format("csv").option("header", "true").load("/home/maciej/Desktop/spark_and_cassandra/sensors.csv")<br/>val sensorReads = spark.read.format("csv").option("header", "true").load("/home/maciej/Desktop/spark_and_cassandra/sensor_reads.csv")</span></pre><h2 id="debc" class="mo lh je bd li mu mv dn lm mw mx dp lq km my mz lu kq na nb ly ku nc nd mc ne bi translated">å†™å…¥ä¼ æ„Ÿå™¨è¡¨</h2><p id="b14f" class="pw-post-body-paragraph kb kc je kd b ke me kg kh ki mf kk kl km mg ko kp kq mh ks kt ku mi kw kx ky im bi translated">åˆ—çš„ç±»å‹å’Œåç§°éƒ½ä¸€è‡´ï¼Œæ‰€ä»¥æ“ä½œå¾ˆç®€å•ã€‚</p><pre class="la lb lc ld gt mj mk ml mm aw mn bi"><span id="0804" class="mo lh je mk b gy mp mq l mr ms">sensors.write<br/>    .format("org.apache.spark.sql.cassandra")<br/>    .option("keyspace","spark_playground")<br/>    .option("table","sensors")<br/>    .mode("append")<br/>    .save()</span></pre><h2 id="bea6" class="mo lh je bd li mu mv dn lm mw mx dp lq km my mz lu kq na nb ly ku nc nd mc ne bi translated">å†™å…¥ä¼ æ„Ÿå™¨è¯»å–è¡¨</h2><p id="b265" class="pw-post-body-paragraph kb kc je kd b ke me kg kh ki mf kk kl km mg ko kp kq mh ks kt ku mi kw kx ky im bi translated">è¿™é‡Œå˜å¾—æ›´åŠ å¤æ‚:</p><ul class=""><li id="c4a9" class="nf ng je kd b ke kf ki kj km nh kq ni ku nj ky nk nl nm nn bi translated">æ¸©åº¦åˆ—ä¸­çš„åˆ—åä¸ä¸€è‡´ã€‚æ¸©åº¦= &gt;æ¸©åº¦</li><li id="2990" class="nf ng je kd b ke no ki np km nq kq nr ku ns ky nk nl nm nn bi translated">æ—¥æœŸåˆ—ä¸­çš„ç±»å‹ä¸ä¸€è‡´ã€‚æˆ‘ä»¬ä»CSVä¸­è¯»å–å­—ç¬¦ä¸²å½¢å¼çš„æ—¥æœŸï¼Œè€ŒCassandraä¸­çš„åˆ—ç±»å‹æ˜¯timeuuidã€‚æˆ‘ä»¬éœ€è¦ä½¿ç”¨Cassandraçš„å®¢æˆ·ç«¯åº“æ¥è¿›è¡Œè½¬æ¢ã€‚</li></ul><p id="4fd7" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">ç±»å‹ä¸ä¸€è‡´çš„é—®é¢˜å¯ä»¥é€šè¿‡é€‚å½“çš„UDF(ç”¨æˆ·å®šä¹‰çš„å‡½æ•°)æ¥è§£å†³ã€‚é¡ºä¾¿è¯´ä¸€ä¸‹ï¼Œæˆ‘ä»¬å°†æ£€æŸ¥åå‘å‡½æ•°æ˜¯å¦è¿”å›ç›¸åŒçš„æ—¥æœŸã€‚é€šå¸¸æˆ‘ä¼šç”¨IntelliJç¼–å†™ä¸€ä¸ªæµ‹è¯•ï¼Œä½†æ˜¯è®©æˆ‘ä»¬ç”¨spark-shellçš„æ–¹å¼æ¥åšğŸ˜Šã€‚</p><pre class="la lb lc ld gt mj mk ml mm aw mn bi"><span id="1be1" class="mo lh je mk b gy mp mq l mr ms">import spark.implicits._<br/>import com.datastax.driver.core.utils.UUIDs<br/>import org.apache.spark.sql.functions.udf<br/> <br/>val toTimeuuid: java.sql.Timestamp =&gt; String = x =&gt; UUIDs.startOf(x.getTime()).toString()<br/>val fromTimeuuid: String =&gt; java.sql.Timestamp = x =&gt; new java.sql.Timestamp(UUIDs.unixTimestamp(java.util.UUID.fromString(x)))<br/> <br/>val toTimeuuidUDF = udf(toTimeuuid)<br/>val fromTimeuuidUDF = udf(fromTimeuuid)<br/> <br/>sensorsReads<br/>    .withColumn("date_as_timestamp", to_timestamp($"date"))<br/>    .withColumn("date_as_timeuuid", toTimeuuidUDF($"date_as_timestamp"))<br/>    .withColumn("timestamp_from_timeuuid",fromTimeuuidUDF($"date_as_timeuuid"))<br/>    .show(false)</span></pre><figure class="la lb lc ld gt iv gh gi paragraph-image"><div class="gh gi nt"><img src="../Images/25e2141eca7f9fc1ea0b1e688c73d535.png" data-original-src="https://miro.medium.com/v2/resize:fit:1324/format:webp/0*a1g7m2gWTj5qIPlu.png"/></div><figcaption class="nu nv gj gh gi nw nx bd b be z dk translated">çœ‹èµ·æ¥ä¸é”™ã€‚</figcaption></figure><p id="8fe7" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">ç°åœ¨æˆ‘ä»¬å»æ‰ä¸å¿…è¦çš„åˆ—ï¼Œé‡å‘½åæ¸©åº¦åˆ—ï¼Œå¹¶å°†æ•°æ®ä¿å­˜åœ¨Cassandraä¸­</p><pre class="la lb lc ld gt mj mk ml mm aw mn bi"><span id="c684" class="mo lh je mk b gy mp mq l mr ms">val sensorsReads_fixed = sensorsReads<br/>                            .withColumn("date_as_timestamp", to_timestamp($"date"))<br/>                            .withColumn("date_as_timeuuid", toTimeuuidUDF($"date_as_timestamp"))<br/>                            .drop("date").drop("date_as_timestamp")<br/>                            .withColumnRenamed("date_as_timeuuid","date")<br/>                            .withColumnRenamed("temperature","temp")<br/>sensorsReads_fixed.write<br/>    .format("org.apache.spark.sql.cassandra")<br/>    .option("keyspace","spark_playground")<br/>    .option("table","sensors_reads")<br/>    .mode("append")<br/>    .save()</span></pre><h1 id="6a46" class="lg lh je bd li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md bi translated">é˜…è¯»å¡çŠå¾·æ‹‰çš„ä½œå“</h1><p id="5ce9" class="pw-post-body-paragraph kb kc je kd b ke me kg kh ki mf kk kl km mg ko kp kq mh ks kt ku mi kw kx ky im bi translated">åœ¨Cassandraä¸­å¯ä»¥ç®€åŒ–å¯¹è¡¨çš„å¼•ç”¨ã€‚æ‚¨åªéœ€è¦é…ç½®Sparkä¸Šä¸‹æ–‡ã€‚</p><pre class="la lb lc ld gt mj mk ml mm aw mn bi"><span id="2dc9" class="mo lh je mk b gy mp mq l mr ms">spark.conf.set("spark.sql.catalog.casscatalog","com.datastax.spark.connector.datasource.CassandraCatalog")</span></pre><p id="b6fd" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">ç°åœ¨æˆ‘ä»¬å¯ä»¥ä½¿ç”¨<em class="mt">cas catalog . key space _ name . table _ name</em>ç¬¦å·æ¥å¼•ç”¨è¿™äº›è¡¨ã€‚</p><pre class="la lb lc ld gt mj mk ml mm aw mn bi"><span id="d6ee" class="mo lh je mk b gy mp mq l mr ms">scala&gt; spark.read.table("casscatalog.spark_playground.sensors").show()<br/>+---------+--------+--------------------+<br/>|sensor_id|group_id|            location|<br/>+---------+--------+--------------------+<br/>|        2|       4|       027 Heath Way|<br/>|       13|       3|  42585 Ramsey Alley|<br/>|        4|       1|     676 Marcy Point|<br/>|        5|       3|260 Steensland Cr...|<br/>|        9|       3|9385 Comanche Ter...|<br/>|        8|       2|291 Meadow Ridge ...|<br/>|        7|       2|     716 Randy Point|<br/>|       14|       2|    331 Mcbride Road|<br/>|       15|       3|     91 Gateway Hill|<br/>|        1|       3|      66 Vera Avenue|<br/>|        6|       4|87212 Lake View S...|<br/>|       12|       2|    12 Montana Place|<br/>|       10|       3|      60 Spohn Plaza|<br/>|       11|       1|    48 Redwing Court|<br/>|        3|       3|        930 Almo Way|<br/>+---------+--------+--------------------+</span><span id="5dfd" class="mo lh je mk b gy ny mq l mr ms"><strong class="mk jf">val</strong> <!-- -->sensors<strong class="mk jf">_</strong>table <strong class="mk jf">=</strong> <!-- -->spark.read.table("casscatalog.spark_playground.sensors")</span><span id="26fb" class="mo lh je mk b gy ny mq l mr ms"><strong class="mk jf">val</strong> <!-- -->sensors<strong class="mk jf">_</strong>reads<strong class="mk jf">_</strong>table <strong class="mk jf">=</strong> <!-- -->spark.read.table("casscatalog.spark_playground.sensors_reads")</span></pre><h2 id="e876" class="mo lh je bd li mu mv dn lm mw mx dp lq km my mz lu kq na nb ly ku nc nd mc ne bi translated">æ‰‹æœ¯è´¹ç”¨</h2><p id="6a0b" class="pw-post-body-paragraph kb kc je kd b ke me kg kh ki mf kk kl km mg ko kp kq mh ks kt ku mi kw kx ky im bi translated">æœ‰äº†Sparkï¼Œä¸€åˆ‡éƒ½æ˜¾å¾—è½»æ¾æ„‰å¿«ã€‚æˆ‘ä»¬å¿…é¡»è®°ä½ï¼Œæˆ‘ä»¬æ“ä½œçš„æ˜¯Cassandraï¼Œå®ƒæœ‰è‡ªå·±å¤„ç†æŸ¥è¯¢çš„æ–¹å¼ã€‚æˆ‘ä¸»è¦å…³å¿ƒé€šè¿‡é”®å’Œå€¼æ£€ç´¢è®°å½•çš„é€Ÿåº¦ã€‚</p><pre class="la lb lc ld gt mj mk ml mm aw mn bi"><span id="fe77" class="mo lh je mk b gy mp mq l mr ms">scala&gt; sensors_table.filter("sensor_id in (1,2,3)").select("sensor_id","location").explain<br/>20/07/21 11:09:50 INFO V2ScanRelationPushDown:<br/>Pushing operators to sensors<br/>Pushed Filters: In(sensor_id, [1,2,3])<br/>Post-Scan Filters:<br/>Output: sensor_id#749, location#751<br/>          <br/>== Physical Plan ==<br/>*(1) Project [sensor_id#749, location#751]<br/>+- BatchScan[sensor_id#749, location#751] Cassandra Scan: spark_playground.sensors<br/> - Cassandra Filters: [["sensor_id" IN (?, ?, ?), 1]]<br/> - Requested Columns: [sensor_id,location]</span></pre><p id="595a" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">é€šè¿‡sensor_idè¿‡æ»¤å‘ç”Ÿåœ¨ä»Cassandraæ£€ç´¢æ•°æ®çš„é˜¶æ®µã€‚æŒ‰group_idè¿‡æ»¤éœ€è¦æŒ‰Sparkæ‰«ææ•´ä¸ªè¡¨ã€‚</p><pre class="la lb lc ld gt mj mk ml mm aw mn bi"><span id="ca37" class="mo lh je mk b gy mp mq l mr ms">scala&gt; sensors_table.filter("group_id in (1,2,3)").select("sensor_id","location").explain<br/>20/07/21 11:14:34 INFO V2ScanRelationPushDown:<br/>Pushing operators to sensors<br/>Pushed Filters:<br/>Post-Scan Filters: group_id#750 IN (1,2,3)<br/>Output: sensor_id#749, group_id#750, location#751<br/>          <br/>== Physical Plan ==<br/>*(1) Project [sensor_id#749, location#751]<br/>+- *(1) Filter group_id#750 IN (1,2,3)<br/>   +- BatchScan[sensor_id#749, group_id#750, location#751] Cassandra Scan: spark_playground.sensors<br/> - Cassandra Filters: []<br/> - Requested Columns: [sensor_id,group_id,location]</span></pre><h2 id="f1a1" class="mo lh je bd li mu mv dn lm mw mx dp lq km my mz lu kq na nb ly ku nc nd mc ne bi translated">ç®€å•èšåˆ</h2><p id="e6cf" class="pw-post-body-paragraph kb kc je kd b ke me kg kh ki mf kk kl km mg ko kp kq mh ks kt ku mi kw kx ky im bi translated">è®©æˆ‘ä»¬å‡è®¾éœ€è¦è®¡ç®—ä¼ æ„Ÿå™¨ç»„çš„æ•°é‡ã€‚æˆ‘ä»¬æ²¡æœ‰åœ¨æ•°æ®åº“è®¾è®¡çº§åˆ«é¢„æµ‹åˆ°è¿™ä¸€ç‚¹ï¼ŒCQLæŸ¥è¯¢ä¹Ÿä¸ä¼šè¢«æ‰§è¡Œã€‚</p><pre class="la lb lc ld gt mj mk ml mm aw mn bi"><span id="6646" class="mo lh je mk b gy mp mq l mr ms">cqlsh:spark_playground&gt; SELECT group_id, count(1) FROM sensors GROUP BY group_id;<br/>InvalidRequest: Error from server: code=2200 [Invalid query] message="Group by is currently only supported on the columns of the PRIMARY KEY, got group_id"</span></pre><p id="0233" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">å› æ­¤ï¼Œæˆ‘ä»¬è¦ä¹ˆåœ¨å®¢æˆ·ç«¯åº”ç”¨ç¨‹åºç«¯è¿›è¡Œï¼Œè¦ä¹ˆä½¿ç”¨Apache Sparkã€‚</p><pre class="la lb lc ld gt mj mk ml mm aw mn bi"><span id="b8e9" class="mo lh je mk b gy mp mq l mr ms">scala&gt; sensors_table.groupBy("group_id").count.show<br/>+--------+-----+                                                                <br/>|group_id|count|<br/>+--------+-----+<br/>|       1|    2|<br/>|       3|    7|<br/>|       4|    2|<br/>|       2|    4|<br/>+--------+-----+</span></pre><h2 id="ab5d" class="mo lh je bd li mu mv dn lm mw mx dp lq km my mz lu kq na nb ly ku nc nd mc ne bi translated">è¿æ¥joinWithCassandraTable</h2><p id="d508" class="pw-post-body-paragraph kb kc je kd b ke me kg kh ki mf kk kl km mg ko kp kq mh ks kt ku mi kw kx ky im bi translated">æœ€ç®€å•çš„è¿æ¥æ–¹æ³•æ˜¯å–ä¸¤ä¸ªé›†åˆï¼Œåšä¸€ä¸ªç¬›å¡å°”ç§¯ã€‚ç„¶è€Œï¼ŒCassandraè¿æ¥å™¨æä¾›äº†ä¸€ä¸ªæ›´å¿«çš„è§£å†³æ–¹æ¡ˆã€‚åœ¨RDDç‰ˆæœ¬ä¸­æœ‰ä¸€ä¸ª<a class="ae kz" href="https://github.com/datastax/spark-cassandra-connector/blob/master/doc/2_loading.md#using-joinwithcassandratable" rel="noopener ugc nofollow" target="_blank">joinwithcassandrable</a>æ–¹æ³•ï¼Œè€Œåœ¨æ•°æ®æ¡†æ¶ä¸­æœ‰<a class="ae kz" href="https://github.com/datastax/spark-cassandra-connector/blob/master/doc/14_data_frames.md#direct-join" rel="noopener ugc nofollow" target="_blank"> Direct Join </a>ï¼Œæ­£å¦‚ä½ æ‰€çœ‹åˆ°çš„ï¼Œå®ƒçš„æ–‡æ¡£å¾ˆå·®ã€‚joinWithCassandraTableä¸ºæºRDDæ‰€éœ€çš„æ¯ä¸ªåˆ†åŒºæ‰§è¡Œä¸€æ¬¡æŸ¥è¯¢ã€‚åœ¨æ•°æ®å¸§çš„æƒ…å†µä¸‹ï¼Œè¿™æ˜¯è‡ªåŠ¨å‘ç”Ÿçš„ã€‚</p><pre class="la lb lc ld gt mj mk ml mm aw mn bi"><span id="933e" class="mo lh je mk b gy mp mq l mr ms">scala&gt; sensors_reads_table.join(sensors_table).explain<br/>...    <br/>== Physical Plan ==<br/>CartesianProduct<br/>:- *(1) Project [date#755, sensor_id#756, humidity#757, temp#758, wind_direction#759, wind_speed#760]<br/>:  +- BatchScan[date#755, sensor_id#756, humidity#757, temp#758, wind_direction#759, wind_speed#760] Cassandra Scan: spark_playground.sensors_reads<br/> - Cassandra Filters: []<br/> - Requested Columns: [date,sensor_id,humidity,temp,wind_direction,wind_speed]<br/>+- *(2) Project [sensor_id#749, group_id#750, location#751]<br/>   +- BatchScan[sensor_id#749, group_id#750, location#751] Cassandra Scan: spark_playground.sensors<br/> - Cassandra Filters: []<br/> - Requested Columns: [sensor_id,group_id,location]</span></pre><p id="fc6d" class="pw-post-body-paragraph kb kc je kd b ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky im bi translated">ç†è®ºä¸Šï¼Œç›¸åŒçš„æ“ä½œï¼Œä½†æ˜¯é€‰æ‹©é”®æ§å…³èŠ‚ä¼šç”Ÿæˆæ›´æœ‰æ•ˆçš„æ‰§è¡Œè®¡åˆ’ã€‚</p><pre class="la lb lc ld gt mj mk ml mm aw mn bi"><span id="138a" class="mo lh je mk b gy mp mq l mr ms">scala&gt; sensors_reads_table.join(sensors_table, sensors_reads_table("sensor_id") === sensors_table("sensor_id"), "inner").explain<br/>...<br/>== Physical Plan ==<br/>*(5) SortMergeJoin [sensor_id#756], [sensor_id#749], Inner<br/>:- *(2) Sort [sensor_id#756 ASC NULLS FIRST], false, 0<br/>:  +- Exchange hashpartitioning(sensor_id#756, 200), true, [id=#812]<br/>:     +- *(1) Project [date#755, sensor_id#756, humidity#757, temp#758, wind_direction#759, wind_speed#760]<br/>:        +- BatchScan[date#755, sensor_id#756, humidity#757, temp#758, wind_direction#759, wind_speed#760] Cassandra Scan: spark_playground.sensors_reads<br/> - Cassandra Filters: []<br/> - Requested Columns: [date,sensor_id,humidity,temp,wind_direction,wind_speed]<br/>+- *(4) Sort [sensor_id#749 ASC NULLS FIRST], false, 0<br/>   +- Exchange hashpartitioning(sensor_id#749, 200), true, [id=#820]<br/>      +- *(3) Project [sensor_id#749, group_id#750, location#751]<br/>         +- BatchScan[sensor_id#749, group_id#750, location#751] Cassandra Scan: spark_playground.sensors<br/> - Cassandra Filters: []<br/> - Requested Columns: [sensor_id,group_id,location]</span></pre><h1 id="b4f7" class="lg lh je bd li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md bi translated">ç¼–è¾‘(2020å¹´7æœˆ30æ—¥)</h1><p id="1658" class="pw-post-body-paragraph kb kc je kd b ke me kg kh ki mf kk kl km mg ko kp kq mh ks kt ku mi kw kx ky im bi translated">Datastaxçš„Alex Ottåœ¨Linkedinçš„è¯„è®ºä¸­å‘Šè¯‰æˆ‘ï¼Œåœ¨è¿™ä¸ªæ¡ˆä¾‹ä¸­æ²¡æœ‰ç›´æ¥åŠ å…¥ã€‚åŸæ¥ä½ éœ€è¦é…ç½®spark.sql.extensionsï¼Œæ›´å¤šè¯¦æƒ…å¯ä»¥åœ¨è¿™é‡Œ<a class="ae kz" href="https://www.datastax.com/blog/2020/05/advanced-apache-cassandra-analytics-now-open-all" rel="noopener ugc nofollow" target="_blank">æ‰¾åˆ°</a>ã€‚</p><pre class="la lb lc ld gt mj mk ml mm aw mn bi"><span id="20fc" class="mo lh je mk b gy mp mq l mr ms">spark.conf.set("spark.sql.extensions", "com.datastax.spark.connector.CassandraSparkExtensions")</span></pre><h1 id="f451" class="lg lh je bd li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md bi translated">è´®è—å®¤ËŒä»“åº“</h1><p id="d1ed" class="pw-post-body-paragraph kb kc je kd b ke me kg kh ki mf kk kl km mg ko kp kq mh ks kt ku mi kw kx ky im bi translated"><a class="ae kz" href="https://github.com/zorteran/wiadro-danych-spark-cassandra-101" rel="noopener ugc nofollow" target="_blank">https://github . com/zorteran/wiadro-danych-spark-Cassandra-101</a>â€”docker-composeå’ŒCSV</p><h1 id="f846" class="lg lh je bd li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md bi translated">æ‘˜è¦</h1><p id="c8d7" class="pw-post-body-paragraph kb kc je kd b ke me kg kh ki mf kk kl km mg ko kp kq mh ks kt ku mi kw kx ky im bi translated">Sparkå’ŒCassandraåˆä½œçš„è¯é¢˜åœ¨è¿™ä¸ªè¯æ¡ä¸­å‡ ä¹æ²¡æœ‰æåŠã€‚Cassandraæ˜¯Hadoopç”Ÿæ€ç³»ç»Ÿçš„ä¸€ä¸ªæœ‰è¶£çš„æ›¿ä»£å’Œ/æˆ–è¡¥å……ã€‚æˆ‘ä»¬å¯ä»¥ä½¿ç”¨Sparkè¿›è¡Œåˆ†æï¼Œä¹Ÿå¯ä»¥ç»´æŠ¤å’Œé›†æˆCassandraçš„æ•°æ®ã€‚æ¯•ç«Ÿï¼Œåœ¨ç¬¬ä¸€ç§æ–¹æ³•ä¸­å¾ˆéš¾æ‰¾åˆ°ç†æƒ³çš„æ•°æ®æ¨¡å‹ğŸ˜‰ã€‚</p></div></div>    
</body>
</html>